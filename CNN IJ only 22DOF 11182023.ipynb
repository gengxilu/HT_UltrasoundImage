{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment \n",
    "import os, glob\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Neural network\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data: read US image data\n",
    "VideoName1GL = [\"USImages/IJ_video1GL*\", \"USImages_22DOF/IJ_GLvideo1_NewAdjunctions_*\"]\n",
    "CompressionRatio = 2\n",
    "Folder =  'E:/ultrasound hand gesture recognition/10142023/'\n",
    "\n",
    "Data = np.empty([0,int(300/CompressionRatio),int(500/CompressionRatio)]) # initiate data space\n",
    "for MoveInd in VideoName1GL: \n",
    "# MoveInd = \"IJ_video1GL*\"\n",
    "    FileList = glob.glob(Folder+MoveInd)    # read ultrasound images, all images were save as 300 rows and 500 columns. shape = (300, 500)\n",
    "    Data_temp = np.zeros((len(FileList), int(300/CompressionRatio),int(500/CompressionRatio))) \n",
    "    temp_ind = 0\n",
    "    for iFile in FileList:\n",
    "        # print(iFile)\n",
    "        tempdata =  np.loadtxt(iFile, dtype = float, delimiter=\",\")\n",
    "        # Data_temp[temp_ind] = tempdata[::CompressionRatio,::CompressionRatio].flatten(order = 'C')\n",
    "        Data_temp[temp_ind] = tempdata[::CompressionRatio,::CompressionRatio].reshape(1,150,250)\n",
    "        temp_ind = temp_ind +1\n",
    "    Data = np.concatenate((Data, Data_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7659, 150, 250), (7659, 22))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output data\n",
    "ModelOutput = np.empty([0,22])\n",
    "\n",
    "HandFiles = [\"IJ_video1GL\", \"IJ_new1029_adjunctions_22DOF_GL\"]\n",
    "for indHand in HandFiles:\n",
    "# indHand = \"IJ_video1GL\"\n",
    "    JointAngles = np.loadtxt(Folder+'Tracked data 22DOF/'+indHand+'.txt', dtype = float,delimiter=\",\")\n",
    "    ModelOutput = np.concatenate((ModelOutput, JointAngles[:,1:]))\n",
    "\n",
    "Data.shape, ModelOutput.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2297, 150, 250) (5362, 150, 250) (2297, 22) (5362, 22) (5362, 22)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset and preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(USImagelist, ModelOutput, test_size=0.3, random_state=2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data, ModelOutput, test_size=0.7, random_state=2)\n",
    "\n",
    "y_predict = np.zeros((len(X_test),Y_train.shape[1]))\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape, y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import zeros, newaxis\n",
    "# class HGDataset(Dataset):\n",
    "#     def __init__(self, img_dir, Y, transform=None, target_transform=None):\n",
    "#         self.img_dir = img_dir\n",
    "#         self.modeloutput = Y\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.modeloutput.shape[0]\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = Folder + 'USImage_All_preprocessed/' + self.img_dir[idx]\n",
    "#         image = np.loadtxt(img_path,dtype = float,delimiter=\",\").astype(np.float32).reshape(1,300,522)\n",
    "#         # print(image.shape)\n",
    "#         output = self.modeloutput[idx].astype(np.float32)\n",
    "#         return image, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None, target_transform=None):\n",
    "        self.data = X\n",
    "        self.modeloutput = Y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.modeloutput.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.data[idx].astype(np.float32).reshape(1,Data.shape[1],Data.shape[2])\n",
    "        output = self.modeloutput[idx].astype(np.float32)\n",
    "        # if self.transform:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform:\n",
    "        #     label = self.target_transform(label)\n",
    "        return input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 150, 250]), torch.float32\n",
      "Shape of y: torch.Size([64, 22]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(HGDataset(X_train, Y_train), batch_size=batch_size);\n",
    "test_dataloader = DataLoader(HGDataset(X_test, Y_test), batch_size=batch_size);\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}, {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "# device = (\n",
    "#     \"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "device = \"cuda\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultioutputCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=140544, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=22, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultioutputCNN(nn.Module):\n",
    "    def __init__(self, output_size=22):\n",
    "        super(MultioutputCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Input: 1 channel, Output: 32 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(140544, 128),  # Adjust the size here according to the output of the last MaxPool layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_CNN = MultioutputCNN(output_size=22).to(device)\n",
    "print(model_CNN)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_CNN.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "modelResnet = resnet18()\n",
    "print(modelResnet)\n",
    "for name, child in modelResnet.named_children():\n",
    "        for x, y in child.named_children():\n",
    "            print(name,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.to(\"cpu\").detach().numpy(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn, loss_ind, loss_value):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            # loss = loss_fn(pred, y)\n",
    "            test_loss += loss_fn(pred, y).item()*len(y)\n",
    "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    # correct /= size\n",
    "    # loss_value[loss_ind-1] = loss.detach().numpy()\n",
    "    loss_value[loss_ind-1] = test_loss\n",
    "    print(\"Loss in test: \")\n",
    "    print(test_loss)\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 183.310181  [   64/ 2297]\n",
      "loss: 26.519180  [  704/ 2297]\n",
      "loss: 24.359034  [ 1344/ 2297]\n",
      "loss: 14.794909  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "15.407191045690677\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 16.890860  [   64/ 2297]\n",
      "loss: 11.378689  [  704/ 2297]\n",
      "loss: 13.894423  [ 1344/ 2297]\n",
      "loss: 10.803879  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "9.824308192271966\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 10.330441  [   64/ 2297]\n",
      "loss: 7.207392  [  704/ 2297]\n",
      "loss: 9.497149  [ 1344/ 2297]\n",
      "loss: 9.208567  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "7.2424151912548345\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 7.495477  [   64/ 2297]\n",
      "loss: 5.406068  [  704/ 2297]\n",
      "loss: 6.875581  [ 1344/ 2297]\n",
      "loss: 7.133189  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "5.620384208660702\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 5.876733  [   64/ 2297]\n",
      "loss: 4.387579  [  704/ 2297]\n",
      "loss: 4.973528  [ 1344/ 2297]\n",
      "loss: 5.469513  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "4.481880371093038\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.641980  [   64/ 2297]\n",
      "loss: 3.744500  [  704/ 2297]\n",
      "loss: 3.944671  [ 1344/ 2297]\n",
      "loss: 4.388113  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "3.80652094243045\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.913114  [   64/ 2297]\n",
      "loss: 3.328839  [  704/ 2297]\n",
      "loss: 3.189584  [ 1344/ 2297]\n",
      "loss: 3.657819  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "3.330190477332087\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.417337  [   64/ 2297]\n",
      "loss: 2.982090  [  704/ 2297]\n",
      "loss: 2.642355  [ 1344/ 2297]\n",
      "loss: 3.135978  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "2.9691344926891734\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.997700  [   64/ 2297]\n",
      "loss: 2.630156  [  704/ 2297]\n",
      "loss: 2.231381  [ 1344/ 2297]\n",
      "loss: 2.737418  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "2.656065822625863\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.630714  [   64/ 2297]\n",
      "loss: 2.310923  [  704/ 2297]\n",
      "loss: 1.882897  [ 1344/ 2297]\n",
      "loss: 2.394876  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "2.3842602447981447\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.307374  [   64/ 2297]\n",
      "loss: 2.030768  [  704/ 2297]\n",
      "loss: 1.599894  [ 1344/ 2297]\n",
      "loss: 2.081874  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "2.158598821895063\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.044618  [   64/ 2297]\n",
      "loss: 1.776646  [  704/ 2297]\n",
      "loss: 1.370679  [ 1344/ 2297]\n",
      "loss: 1.828845  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.9788667064511656\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.840086  [   64/ 2297]\n",
      "loss: 1.584591  [  704/ 2297]\n",
      "loss: 1.225421  [ 1344/ 2297]\n",
      "loss: 1.625622  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.845176937597005\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.665039  [   64/ 2297]\n",
      "loss: 1.415190  [  704/ 2297]\n",
      "loss: 1.207832  [ 1344/ 2297]\n",
      "loss: 1.500749  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.8531950280898455\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.617226  [   64/ 2297]\n",
      "loss: 1.351999  [  704/ 2297]\n",
      "loss: 1.186785  [ 1344/ 2297]\n",
      "loss: 1.424049  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.8980981834963693\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.631685  [   64/ 2297]\n",
      "loss: 1.600529  [  704/ 2297]\n",
      "loss: 1.451776  [ 1344/ 2297]\n",
      "loss: 1.948976  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.9524869819667436\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.794858  [   64/ 2297]\n",
      "loss: 1.449639  [  704/ 2297]\n",
      "loss: 1.385854  [ 1344/ 2297]\n",
      "loss: 1.204205  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.7130143582843125\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.515529  [   64/ 2297]\n",
      "loss: 1.136509  [  704/ 2297]\n",
      "loss: 0.939597  [ 1344/ 2297]\n",
      "loss: 1.101266  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.5051152857547818\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.231646  [   64/ 2297]\n",
      "loss: 0.964327  [  704/ 2297]\n",
      "loss: 0.815772  [ 1344/ 2297]\n",
      "loss: 0.993915  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.4440979245481809\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.132795  [   64/ 2297]\n",
      "loss: 0.888099  [  704/ 2297]\n",
      "loss: 0.748839  [ 1344/ 2297]\n",
      "loss: 0.921219  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.4078535776625636\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.055614  [   64/ 2297]\n",
      "loss: 0.848452  [  704/ 2297]\n",
      "loss: 0.711047  [ 1344/ 2297]\n",
      "loss: 0.861882  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3876157696902507\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.992101  [   64/ 2297]\n",
      "loss: 0.829414  [  704/ 2297]\n",
      "loss: 0.711156  [ 1344/ 2297]\n",
      "loss: 0.869835  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.425051115422674\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.982202  [   64/ 2297]\n",
      "loss: 0.863209  [  704/ 2297]\n",
      "loss: 0.731093  [ 1344/ 2297]\n",
      "loss: 0.909756  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.506286493169421\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.041901  [   64/ 2297]\n",
      "loss: 1.091587  [  704/ 2297]\n",
      "loss: 0.865723  [ 1344/ 2297]\n",
      "loss: 0.946083  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.5282418424849278\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.123230  [   64/ 2297]\n",
      "loss: 0.957841  [  704/ 2297]\n",
      "loss: 0.730002  [ 1344/ 2297]\n",
      "loss: 0.866919  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.4201542620381415\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.948482  [   64/ 2297]\n",
      "loss: 0.797066  [  704/ 2297]\n",
      "loss: 0.694498  [ 1344/ 2297]\n",
      "loss: 0.751806  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3652607481099919\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.851159  [   64/ 2297]\n",
      "loss: 0.830808  [  704/ 2297]\n",
      "loss: 0.697234  [ 1344/ 2297]\n",
      "loss: 0.679178  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3835223455430856\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.838005  [   64/ 2297]\n",
      "loss: 0.890721  [  704/ 2297]\n",
      "loss: 0.729721  [ 1344/ 2297]\n",
      "loss: 0.681740  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.7078813397586456\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.097595  [   64/ 2297]\n",
      "loss: 1.240870  [  704/ 2297]\n",
      "loss: 0.653050  [ 1344/ 2297]\n",
      "loss: 0.924058  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3347403577840493\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.800218  [   64/ 2297]\n",
      "loss: 0.842595  [  704/ 2297]\n",
      "loss: 1.961173  [ 1344/ 2297]\n",
      "loss: 2.088995  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.660111232085799\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.082441  [   64/ 2297]\n",
      "loss: 1.070663  [  704/ 2297]\n",
      "loss: 0.788046  [ 1344/ 2297]\n",
      "loss: 1.158484  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.628076448097286\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.225895  [   64/ 2297]\n",
      "loss: 0.743823  [  704/ 2297]\n",
      "loss: 0.515228  [ 1344/ 2297]\n",
      "loss: 0.824771  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.43105119153307\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.851344  [   64/ 2297]\n",
      "loss: 0.600250  [  704/ 2297]\n",
      "loss: 0.456381  [ 1344/ 2297]\n",
      "loss: 0.740742  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3844366074497687\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.787033  [   64/ 2297]\n",
      "loss: 0.537548  [  704/ 2297]\n",
      "loss: 0.450140  [ 1344/ 2297]\n",
      "loss: 0.698794  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3207839059989783\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.724538  [   64/ 2297]\n",
      "loss: 0.536531  [  704/ 2297]\n",
      "loss: 0.486415  [ 1344/ 2297]\n",
      "loss: 0.638967  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2786567476826434\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.683343  [   64/ 2297]\n",
      "loss: 0.618412  [  704/ 2297]\n",
      "loss: 0.526524  [ 1344/ 2297]\n",
      "loss: 0.550867  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.260026924337126\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.661756  [   64/ 2297]\n",
      "loss: 0.620670  [  704/ 2297]\n",
      "loss: 0.541500  [ 1344/ 2297]\n",
      "loss: 0.579057  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2382492207404794\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.629707  [   64/ 2297]\n",
      "loss: 0.477925  [  704/ 2297]\n",
      "loss: 0.491413  [ 1344/ 2297]\n",
      "loss: 0.563996  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2651742726775614\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.638703  [   64/ 2297]\n",
      "loss: 0.473727  [  704/ 2297]\n",
      "loss: 0.418654  [ 1344/ 2297]\n",
      "loss: 0.432753  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2658435955326843\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.618414  [   64/ 2297]\n",
      "loss: 0.506274  [  704/ 2297]\n",
      "loss: 0.370772  [ 1344/ 2297]\n",
      "loss: 0.472092  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2037641805350359\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.547505  [   64/ 2297]\n",
      "loss: 0.422927  [  704/ 2297]\n",
      "loss: 0.383460  [ 1344/ 2297]\n",
      "loss: 0.514452  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.1580808074871847\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.499304  [   64/ 2297]\n",
      "loss: 0.392183  [  704/ 2297]\n",
      "loss: 0.414622  [ 1344/ 2297]\n",
      "loss: 0.486124  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.1633146291613268\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.496315  [   64/ 2297]\n",
      "loss: 0.425234  [  704/ 2297]\n",
      "loss: 0.438569  [ 1344/ 2297]\n",
      "loss: 0.463390  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2048245113494458\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.520454  [   64/ 2297]\n",
      "loss: 0.464298  [  704/ 2297]\n",
      "loss: 0.466983  [ 1344/ 2297]\n",
      "loss: 0.516624  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3065049913960223\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.604577  [   64/ 2297]\n",
      "loss: 0.430181  [  704/ 2297]\n",
      "loss: 0.400330  [ 1344/ 2297]\n",
      "loss: 0.558032  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.5118628643822731\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.780659  [   64/ 2297]\n",
      "loss: 0.511823  [  704/ 2297]\n",
      "loss: 0.539966  [ 1344/ 2297]\n",
      "loss: 0.502320  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.3381945328319398\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.609529  [   64/ 2297]\n",
      "loss: 0.564089  [  704/ 2297]\n",
      "loss: 0.565111  [ 1344/ 2297]\n",
      "loss: 0.600869  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2470455763500958\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.591414  [   64/ 2297]\n",
      "loss: 0.521195  [  704/ 2297]\n",
      "loss: 0.455362  [ 1344/ 2297]\n",
      "loss: 0.474475  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2984746557169555\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.643663  [   64/ 2297]\n",
      "loss: 0.562716  [  704/ 2297]\n",
      "loss: 0.527384  [ 1344/ 2297]\n",
      "loss: 0.492797  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.2001714810245476\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.559173  [   64/ 2297]\n",
      "loss: 0.404691  [  704/ 2297]\n",
      "loss: 0.405551  [ 1344/ 2297]\n",
      "loss: 0.375243  [ 1984/ 2297]\n",
      "Loss in test: \n",
      "1.1740437262052033\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1407fdef2e0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 50\n",
    "loss_value = np.zeros(epochs)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model_CNN, loss_fn, optimizer)\n",
    "    test(test_dataloader, model_CNN, loss_fn, t, loss_value)\n",
    "print(\"Done!\")\n",
    "# test(test_dataloader, model_CNN, loss_fn, t, loss_value)\n",
    "plt.plot(range(epochs-1), loss_value[:-1], color =\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average processing time per image:  0.17845332733689293 ms\n",
      "the mean error is: 0.709462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.41660345, 0.96418344, 1.02730378, 0.56469133, 0.71815655,\n",
       "       0.52130821, 0.86990579, 1.08793986, 0.63525501, 0.43149891,\n",
       "       0.80501431, 0.86639816, 0.51646618, 0.41813543, 0.65261352,\n",
       "       0.71836409, 0.51503112, 0.46482905, 0.95816931, 0.98730366,\n",
       "       1.06531313, 0.40367261])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use trained model to predict on test data\n",
    "\n",
    "import time\n",
    "ind_batch = 0\n",
    "y_predict_CNN = np.zeros(y_predict.shape)\n",
    "\n",
    "startTime = time.time()\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_predict_CNN[ind_batch*batch_size:ind_batch*batch_size+len(y)] = model_CNN(X).to(\"cpu\")\n",
    "        ind_batch +=1 \n",
    "endTime = time.time()\n",
    "print('average processing time per image: ', (endTime- startTime)/y_predict_CNN.shape[0]*1000, 'ms')\n",
    "\n",
    "E_CNN = abs(y_predict_CNN-Y_test)\n",
    "MeanE_CNN = np.mean(E_CNN, axis=0)\n",
    "print(f\"the mean error is: {np.mean(MeanE_CNN):>7f}\")\n",
    "MeanE_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average processing time per image:  0.17598677995170994 ms\n"
     ]
    }
   ],
   "source": [
    "# use trained model to predict all data\n",
    "yAll_predict_CNN = np.zeros(ModelOutput.shape)\n",
    "ind_batch = 0\n",
    "All_dataloader = DataLoader(HGDataset(Data, ModelOutput), batch_size=batch_size) \n",
    "\n",
    "startTime = time.time()\n",
    "with torch.no_grad():\n",
    "    for X, y in All_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        yAll_predict_CNN[ind_batch*batch_size:ind_batch*batch_size+len(y)] = model_CNN(X).to(\"cpu\")\n",
    "        ind_batch +=1\n",
    "endTime = time.time()\n",
    "print('average processing time per image: ', (endTime- startTime)/yAll_predict_CNN.shape[0]*1000, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveFolder =  Folder+'ML results/IndividualJoint1GL_22DOF/'\n",
    "\n",
    "np.savetxt(SaveFolder+'ypredict_CNNBatch64Epoch50_'+str(pow(CompressionRatio, 2))+'compression.txt', y_predict_CNN, fmt='%f')\n",
    "np.savetxt(SaveFolder+'ytest_CNN_'+str(pow(CompressionRatio, 2))+'compression.txt', Y_test, fmt='%f')\n",
    "\n",
    "np.savetxt(SaveFolder+'ypredict_all_CNNBatch64Epoch50_'+str(pow(CompressionRatio, 2))+'compression.txt', yAll_predict_CNN, fmt='%f')\n",
    "np.savetxt(SaveFolder+'Y_All.txt', ModelOutput, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_CNN.state_dict(), Folder+'ML results/model_CNN_IJonly_22DOF.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
